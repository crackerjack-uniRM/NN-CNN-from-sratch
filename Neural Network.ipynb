{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31fa3d2d-84c5-4152-b382-57b9c10c717f",
   "metadata": {},
   "source": [
    "# Neural Network From Scratch\n",
    "\n",
    "**Author: rNLKJA**\n",
    "\n",
    "This notebook contains the code & notes for YouTube Video [Neural Network from Scratch | Mathematics & Python Code](https://www.youtube.com/watch?v=pauPCy_s0Ok&t=1671s).\n",
    "\n",
    "You may also find the original codes on [Github](https://github.com/TheIndependentCode/Neural-Network)\n",
    "\n",
    "I might add some notation for better understanding of How Neural Network works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9bee8d-e2ad-4df0-ba3e-7f0352417ea0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Layer\n",
    "\n",
    "A layer will receive an input and produce the output, which means the layer works like an function. \n",
    "\n",
    "<!-- <img src=\"./images/layer1.png\" width=500px/> -->\n",
    "\n",
    "When layer receive an input and produce the output, we called this process a forward propagation. However, when we take the output to update its parameters, we call this backward propagation.\n",
    "\n",
    "To calculate the deriviatives, we could use chain rule which converts the derivatives to another form:\n",
    "\n",
    "$$\n",
    "\\cfrac{\\partial E}{\\partial W} = \\cfrac{\\partial E}{\\partial Y}\\cfrac{\\partial Y}{\\partial W}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\cfrac{\\partial E}{\\partial X} = \\cfrac{\\partial E}{\\partial Y}\\cfrac{\\partial Y}{\\partial X}\n",
    "$$\n",
    "\n",
    "For a neural nework, it constructs by a sequential model, which means current layer output is the input for the next layer.\n",
    "\n",
    "That means assume a network has three layers, then we have: $Y_1 = X_1$, $Y_2 = X_2$, $\\cfrac{\\partial E}{\\partial Y_1} = \\cfrac{\\partial E}{\\partial X_2}$ and $\\cfrac{\\partial E}{\\partial Y_2} = \\cfrac{\\partial E}{\\partial X_3}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d5de9be9-fdc4-4306-8c0a-f17a364ed921",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T09:14:13.701719Z",
     "iopub.status.busy": "2022-04-14T09:14:13.701484Z",
     "iopub.status.idle": "2022-04-14T09:14:13.704657Z",
     "shell.execute_reply": "2022-04-14T09:14:13.704064Z",
     "shell.execute_reply.started": "2022-04-14T09:14:13.701697Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae995d12-7fcf-4973-be29-b9cc64edbb7f",
   "metadata": {},
   "source": [
    "#### Create the base layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43bcef61-32bf-4513-b945-5acc1d5a016a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T07:53:39.923934Z",
     "iopub.status.busy": "2022-04-14T07:53:39.923672Z",
     "iopub.status.idle": "2022-04-14T07:53:39.928262Z",
     "shell.execute_reply": "2022-04-14T07:53:39.927516Z",
     "shell.execute_reply.started": "2022-04-14T07:53:39.923907Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# implmenet the base layer\n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "    \n",
    "    # a forward method takes the input to produce the output\n",
    "    def forward(self, input):\n",
    "        # TODO: return output\n",
    "        pass\n",
    "    \n",
    "    # the backward method takes the output to update its input\n",
    "    # 1. update the training parameters\n",
    "    # 2. return the derivative of error based on the learning rate\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        # TODO: update parameters and return input gradient\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48fb88f-2e10-4a3d-8d99-41bb68992af2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dense Layer\n",
    "\n",
    "A dense layer connects the set of $i$ inputs (e.g. $x_1, x_2, x_3$) to a set of $j$ output (e.g. $y_1, y_2, y_3, y_4$).\n",
    "\n",
    "Each connection represented by a variable weights $w$. We write the notation as $w_{ji}$.\n",
    "\n",
    "In addition we define the bias term $b_j$ for each output. Hence we have the following formulas:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "y_1 = x_1w_{11} + x_2w_{12} + \\dots + x_iw_{1i} + b_1 \\\\\n",
    "y_2 = x_1w_{21} + x_2w_{22} + \\dots + x_iw_{2i} + b_2 \\\\\n",
    "y_3 = x_1w_{31} + x_2w_{32} + \\dots + x_iw_{3i} + b_3 \\\\\n",
    "\\vdots \\\\\n",
    "y_j = x_1w_{j1} + x_2w_{j2} + \\dots + x_iw_{ji} + b_j \\\\\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc262b97-a39b-4f2f-a1e7-85ff5d011077",
   "metadata": {},
   "source": [
    "Then we rewrite these functions use matrices: \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "   y_1 \\\\ y2 \\\\ \\vdots \\\\ y_j\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "    w_{11} & w_{12} & \\dots & w_{1i} \\\\\n",
    "    w_{11} & w_{12} & \\dots & w_{1i} \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    w_{j1} & w_{j2} & \\dots & w_{ji}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_i\n",
    "\\end{bmatrix} + \\begin{bmatrix}b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_j\\end{bmatrix} \\rightarrow Y =W \\cdot X + B\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea7b295-646c-4d7d-bc0d-fd047a877571",
   "metadata": {},
   "source": [
    "For a layer, $W$ and $B$ are trainable parameters. In the mean time we also need to calculate the error.\n",
    "\n",
    "We want to use derivative respect to Y to calculate the derivatives of $W, B, X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eceee1-ed0a-4198-9da0-c861d352ca5c",
   "metadata": {},
   "source": [
    "$$\n",
    "\\cfrac{\\partial E}{\\partial Y} = \\begin{bmatrix}\n",
    " \\cfrac{\\partial E}{\\partial y_1} \\\\ \\cfrac{\\partial E}{\\partial y_2} \\\\ \\vdots \\\\ \\cfrac{\\partial E}{\\partial y_j} \n",
    "\\end{bmatrix} \\rightarrow \\cfrac{\\partial E}{\\partial W} = \\begin{bmatrix}\n",
    "    \\cfrac{\\partial E}{\\partial w_{11}} & \\cfrac{\\partial E}{\\partial w_{12}} & \\dots & \\cfrac{\\partial E}{\\partial w_{1i}} \\\\\n",
    "    \\cfrac{\\partial E}{\\partial w_{21}} & \\cfrac{\\partial E}{\\partial w_{22}} & \\dots & \\cfrac{\\partial E}{\\partial w_{2i}} \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\cfrac{\\partial E}{\\partial w_{j1}} & \\cfrac{\\partial E}{\\partial w_{j2}} & \\dots & \\cfrac{\\partial E}{\\partial w_{ji}} \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f003f37e-a4c5-4471-90ef-93598b641e69",
   "metadata": {},
   "source": [
    "Given the above formulas, then for a single term \n",
    "\n",
    "$$\n",
    "\\cfrac{\\partial E}{\\partial w_{12}} = \\cfrac{\\partial E}{\\partial y_1}\\cfrac{\\partial y_1}{\\partial w_{12}} + \\cfrac{\\partial E}{\\partial y_2} \\cfrac{\\partial y_2}{\\partial w_{12}} + \\dots + \\cfrac{\\partial E}{\\partial y_j}\\cfrac{\\partial y_j}{\\partial w_{12}} = \\cfrac{\\partial E}{\\partial y_1}\\cfrac{\\partial y_1}{\\partial w_{12}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dd53bd-10a8-4eba-9557-3fd4288aec12",
   "metadata": {},
   "source": [
    "Then we can have the following calculation:\n",
    "\n",
    "$$\n",
    "\\cfrac{\\partial E}{\\partial W} = \\begin{bmatrix}\n",
    "    \\cfrac{\\partial E}{\\partial y_1}x_1 & \\cfrac{\\partial E}{\\partial y_1}x_2 & \\dots & \\cfrac{\\partial E}{\\partial y_1}x_1 \\\\\n",
    "    \\cfrac{\\partial E}{\\partial y_1}x_1 & \\cfrac{\\partial E}{\\partial y_2}x_2 & \\dots & \\cfrac{\\partial E}{\\partial y_1}x_2 \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\cfrac{\\partial E}{\\partial y_1}x_1 & \\cfrac{\\partial E}{\\partial y_j}x_2 & \\dots & \\cfrac{\\partial E}{\\partial y_1}x_j \\\\\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "    \\cfrac{\\partial E}{\\partial y_1} \\\\ \\cfrac{\\partial E}{\\partial y_2} \\\\ \\vdots \\\\ \\cfrac{\\partial E}{\\partial y_j}\n",
    "\\end{bmatrix} \\begin{bmatrix}x_1 & x_2 & \\dots & x_i \\end{bmatrix} = \\cfrac{\\partial E}{\\partial Y}\\cdot X^t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc3b991-ee37-4f74-9565-a8a39a38c415",
   "metadata": {},
   "source": [
    "Do the same work for $B$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef75a7ee-6530-4384-a6ce-3500f4be3eda",
   "metadata": {},
   "source": [
    "$$\n",
    "\\cfrac{\\partial E}{\\partial Y} = \\begin{bmatrix}\n",
    "    \\cfrac{\\partial E}{\\partial y_1} \\\\ \\cfrac{\\partial E}{\\partial y_2} \\\\ \\vdots \\\\ \\cfrac{\\partial E}{\\partial y_j} \n",
    "\\end{bmatrix} \\rightarrow \\cfrac{\\partial E}{\\partial B} = \\begin{bmatrix}\n",
    "    \\cfrac{\\partial E}{\\partial b_1} \\\\ \\cfrac{\\partial E}{\\partial b_2} \\\\ \\vdots \\\\ \\cfrac{\\partial E}{\\partial b_j} \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efc3ca7-c637-4100-a922-92eb8ce1cae3",
   "metadata": {},
   "source": [
    "Take an example of $b_1$:\n",
    "\n",
    "$$\n",
    "\\cfrac{\\partial E}{\\partial b_1} = \\cfrac{\\partial E}{\\partial y_1}\\cfrac{\\partial y_1}{\\partial b_1} + \\cfrac{\\partial E}{\\partial y_2}\\cfrac{\\partial y_2}{\\partial b_1}+\\dots+\\cfrac{\\partial E}{\\partial y_j}\\cfrac{\\partial y_j}{\\partial b_1} = \\cfrac{\\partial E}{\\partial y_1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8d8938-23da-4856-b93f-b1c96dd86e3b",
   "metadata": {},
   "source": [
    "$$\n",
    "\\cfrac{\\partial E}{\\partial b_j} = \\cfrac{\\partial E}{\\partial y_j} \\rightarrow \\cfrac{\\partial E}{\\partial B} = \\cfrac{\\partial E}{\\partial Y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6318b6cd-85d5-4d79-b26c-5b9913c4e0ab",
   "metadata": {},
   "source": [
    "The last work is calculate derivatives for X:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc789940-1692-45c6-b81b-60007d8d1543",
   "metadata": {},
   "source": [
    "$$\n",
    "\\cfrac{\\partial E}{\\partial Y} = \\begin{bmatrix}\n",
    "    \\cfrac{\\partial E}{\\partial y_1} \\\\ \\cfrac{\\partial E}{\\partial y_2} \\\\ \\vdots \\\\ \\cfrac{\\partial E}{\\partial y_j} \n",
    "\\end{bmatrix} \\rightarrow \\cfrac{\\partial E}{\\partial X} = \\begin{bmatrix}\n",
    "    \\cfrac{\\partial E}{\\partial x_1} \\\\ \\cfrac{\\partial E}{\\partial x_2} \\\\ \\vdots \\\\ \\cfrac{\\partial E}{\\partial x_j} \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c522eb00-9624-453d-aa85-d079917de385",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        \\cfrac{\\partial E}{\\partial x_i} &= \\cfrac{\\partial E}{\\partial y_1}\\cfrac{\\partial y_1}{\\partial x_1} + \\cfrac{\\partial E}{\\partial y_2}\\cfrac{\\partial y_2}{\\partial x_1} + \\dots + \\cfrac{\\partial E}{\\partial y_j}\\cfrac{\\partial y_j}{\\partial x_1}\n",
    "        &= \\cfrac{\\partial E}{\\partial y_1}w_{1i} + \\cfrac{\\partial E}{\\partial y_1}w_{2i} + \\dots + \\cfrac{\\partial E}{\\partial y_1}w_{ji}\n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0512bb7a-70a1-4228-bcca-2647f9b48ae7",
   "metadata": {},
   "source": [
    "$$\n",
    "\\cfrac{\\partial E}{\\partial X} = \\begin{bmatrix}\n",
    "    \\cfrac{\\partial E}{\\partial y_1}w_{11} + \\cfrac{\\partial E}{\\partial y_2}w_{21} + \\dots + \\cfrac{\\partial E}{\\partial y_j}w_{j1} \\\\\n",
    "    \\cfrac{\\partial E}{\\partial y_1}w_{12} + \\cfrac{\\partial E}{\\partial y_2}w_{22} + \\dots + \\cfrac{\\partial E}{\\partial y_j}w_{j2} \\\\\n",
    "    \\vdots \\\\\n",
    "    \\cfrac{\\partial E}{\\partial y_1}w_{1i} + \\cfrac{\\partial E}{\\partial y_2}w_{2i} + \\dots + \\cfrac{\\partial E}{\\partial y_j}w_{ji} \\\\\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "    w_{11} & w_{21} & \\dots & w_{j1} \\\\\n",
    "    w_{12} & w_{22} & \\dots & w_{j2} \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    w_{1j} & w_{2j} & \\dots & w_{ij} \\\\\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "    \\cfrac{\\partial Y}{\\partial y_1} \\\\ \\cfrac{\\partial Y}{\\partial y_2} \\\\ \\vdots \\\\ \\cfrac{\\partial Y}{\\partial y_j}\n",
    "\\end{bmatrix} = W^t \\cdot \\cfrac{\\partial E}{\\partial Y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a9a5ef-088e-4da7-aa11-e49fd26b1a74",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb74cb96-cb0a-49c4-acc1-34ca6c13078b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T08:48:09.901210Z",
     "iopub.status.busy": "2022-04-14T08:48:09.900962Z",
     "iopub.status.idle": "2022-04-14T08:48:09.906349Z",
     "shell.execute_reply": "2022-04-14T08:48:09.905811Z",
     "shell.execute_reply.started": "2022-04-14T08:48:09.901187Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(output_size, input_size)\n",
    "        self.bias = np.random.randn(output_size, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        The forward method simply calculate the value based on Y = WX + B\n",
    "        \"\"\"\n",
    "        self.input = input\n",
    "        return np.dot(self.weights, self.input) + self.bias\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        \"\"\"\n",
    "        output_gradient: the derivatives of bias => output gradient\n",
    "        \"\"\"\n",
    "        weights_gradient = np.dot(output_gradient, self.input.T) # calculate the derivatives of error with respects to the weights\n",
    "        \n",
    "        self.weights -= learning_rate * weights_gradient\n",
    "        self.bias -= learning_rate * output_gradient\n",
    "        \n",
    "        input_gradient = np.dot(self.weights.T, output_gradient) # calculate the derivatives of X\n",
    "        return input_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e5bc8a-cfa5-4a99-9588-8558dac98f94",
   "metadata": {},
   "source": [
    "### Activation Layer\n",
    "\n",
    "The activation layer takes the number of input to produce the number of outputs based on given activation function. e.g.\n",
    "\n",
    "$$\n",
    "y_1 = f(x_1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b7834a-a583-4f48-b496-01a7f263f088",
   "metadata": {},
   "source": [
    "Then for a forward propagation, we have the fomula: $Y = f(X)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee23bd6c-2f03-48f1-96c1-056f8a927992",
   "metadata": {},
   "source": [
    "And again, in order to update the parameters, we still need to calculate the derivatives: $\\cfrac{\\partial E}{\\partial Y}$ and $\\cfrac{\\partial E}{\\partial X}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1d259c-ccb2-45ce-a98b-2c231abaf259",
   "metadata": {},
   "source": [
    "For $x_1$ we have:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e93d0c6-bc75-4e49-9108-10484e82b120",
   "metadata": {},
   "source": [
    "$$\n",
    "\\cfrac{\\partial E}{\\partial x_1} = \\cfrac{\\partial E}{\\partial y_1}\\cfrac{\\partial y_1}{\\partial x_1} + \\cfrac{\\partial E}{\\partial y_2}\\cfrac{\\partial y_2}{\\partial x_2} + \\dots + \\cfrac{\\partial E}{\\partial y_j}\\cfrac{\\partial y_j}{\\partial x_i} = \\cfrac{\\partial E}{\\partial y_1} f^\\prime(x_1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04f9d1b-b680-4158-bb21-cd439e08c29c",
   "metadata": {},
   "source": [
    "$$\n",
    "\\cfrac{\\partial E}{\\partial Y} = \\cfrac{\\partial E}{\\partial Y} \\odot f^\\prime(X)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b929e721-bb96-49ef-9971-db51830b5f06",
   "metadata": {},
   "source": [
    "$\\odot$: element-wise multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de06d93f-f2e6-4bad-8a0c-ca2cacf2f856",
   "metadata": {},
   "source": [
    "#### Create Activation Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fc963a4-7cc2-4005-8c12-0e1227060565",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T07:03:17.509651Z",
     "iopub.status.busy": "2022-04-14T07:03:17.509296Z",
     "iopub.status.idle": "2022-04-14T07:03:17.513846Z",
     "shell.execute_reply": "2022-04-14T07:03:17.513153Z",
     "shell.execute_reply.started": "2022-04-14T07:03:17.509630Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Activation(Layer):\n",
    "    def __init__(self, activation, activation_prime):\n",
    "        self.activation = activation # activation function\n",
    "        self.activation_prime = activation_prime # derivative of an activatino function\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return self.activation(self.input)\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        return np.multiply(output_gradient, self.activation_prime(self.input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f222a055-4cdc-45ab-8929-527e52fef060",
   "metadata": {},
   "source": [
    "### Implement activation functions and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4582c3e2-64b3-4c78-82c4-dc0fd6db60b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T07:03:46.870635Z",
     "iopub.status.busy": "2022-04-14T07:03:46.870353Z",
     "iopub.status.idle": "2022-04-14T07:03:46.875536Z",
     "shell.execute_reply": "2022-04-14T07:03:46.874507Z",
     "shell.execute_reply.started": "2022-04-14T07:03:46.870607Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperbolic Tangent\n",
    "class Tanh(Activation):\n",
    "    def __init__(self):\n",
    "        tanh = lambda x: np.tanh(x)\n",
    "        tanh_prime = lambda x: 1 - np.tanh(x)**2\n",
    "        super().__init__(tanh, tanh_prime) # call super constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4649c19-badc-4ab4-b1ed-3dd11b28f09a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T07:03:47.179441Z",
     "iopub.status.busy": "2022-04-14T07:03:47.179011Z",
     "iopub.status.idle": "2022-04-14T07:03:47.184488Z",
     "shell.execute_reply": "2022-04-14T07:03:47.183574Z",
     "shell.execute_reply.started": "2022-04-14T07:03:47.179412Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mean Squared Error\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true - y_pred, 2))\n",
    "\n",
    "# Derivative of Mean Squared Error formula\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return 2 * (y_pred - y_true) / np.size(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2e3bab-04ae-4c73-94f3-737533da7e45",
   "metadata": {},
   "source": [
    "### Solve XOR (MINST)\n",
    "\n",
    "Logic gate issue:\n",
    "\n",
    "| $x_1$ | $x_2$ | $y_1$ |\n",
    "| ---- | ---- | ---- |\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1 |\n",
    "| 1 | 0 | 1 |\n",
    "| 1 | 1 | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0871ba11-9ec0-4983-86b8-c354faa616e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T07:03:47.718862Z",
     "iopub.status.busy": "2022-04-14T07:03:47.718586Z",
     "iopub.status.idle": "2022-04-14T07:03:47.723219Z",
     "shell.execute_reply": "2022-04-14T07:03:47.722508Z",
     "shell.execute_reply.started": "2022-04-14T07:03:47.718834Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate sample dataset\n",
    "X = np.reshape([[0, 0], [0, 1], [1, 0], [1, 1]], (4, 2, 1))\n",
    "Y = np.reshape([[0], [1], [1], [0]], (4, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "557e4160-355b-4302-99c9-a7deb27a6bf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T07:03:48.022635Z",
     "iopub.status.busy": "2022-04-14T07:03:48.022344Z",
     "iopub.status.idle": "2022-04-14T07:03:48.030557Z",
     "shell.execute_reply": "2022-04-14T07:03:48.029710Z",
     "shell.execute_reply.started": "2022-04-14T07:03:48.022610Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0],\n",
       "        [0]],\n",
       "\n",
       "       [[0],\n",
       "        [1]],\n",
       "\n",
       "       [[1],\n",
       "        [0]],\n",
       "\n",
       "       [[1],\n",
       "        [1]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[[0]],\n",
       "\n",
       "       [[1]],\n",
       "\n",
       "       [[1]],\n",
       "\n",
       "       [[0]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# inspect the data\n",
    "display(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71989dcf-e2fb-4c44-8e38-08f1c5d15668",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T07:03:48.582057Z",
     "iopub.status.busy": "2022-04-14T07:03:48.581771Z",
     "iopub.status.idle": "2022-04-14T07:03:48.586043Z",
     "shell.execute_reply": "2022-04-14T07:03:48.585283Z",
     "shell.execute_reply.started": "2022-04-14T07:03:48.582028Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# construct the neural network\n",
    "network = [\n",
    "    Dense(2, 3),\n",
    "    Tanh(),\n",
    "    Dense(3, 1),\n",
    "    Tanh()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "49764019-5d4b-4fd8-9c1b-37b492f2ddb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T09:18:52.327275Z",
     "iopub.status.busy": "2022-04-14T09:18:52.327023Z",
     "iopub.status.idle": "2022-04-14T09:18:52.330499Z",
     "shell.execute_reply": "2022-04-14T09:18:52.329801Z",
     "shell.execute_reply.started": "2022-04-14T09:18:52.327250Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "52761bfd-9a6b-4779-b519-3746ea073d5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T09:20:03.216147Z",
     "iopub.status.busy": "2022-04-14T09:20:03.215914Z",
     "iopub.status.idle": "2022-04-14T09:20:21.503004Z",
     "shell.execute_reply": "2022-04-14T09:20:21.501756Z",
     "shell.execute_reply.started": "2022-04-14T09:20:03.216126Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 10000/10000, error=0.00000: 100%|█████████████████████████████████████████| 10000/10000 [00:18<00:00, 547.06it/s]\n"
     ]
    }
   ],
   "source": [
    "p_bar = tqdm(range(epochs))\n",
    "\n",
    "for epoch in p_bar:\n",
    "    error = 0\n",
    "    for x, y in zip(X, Y):\n",
    "        \n",
    "        # perform the forward propagation: compute the output of the neural network\n",
    "        output = x\n",
    "        for layer in network:\n",
    "            output = layer.forward(output)\n",
    "        \n",
    "        # compute the error\n",
    "        error += mse(y, output)\n",
    "        \n",
    "        # perform the backward propagation: learning step\n",
    "        grad = mse_prime(y, output)\n",
    "        for layer in reversed(network):\n",
    "            grad = layer.backward(grad, learning_rate)\n",
    "            \n",
    "    error /= len(X)\n",
    "    p_bar.set_description(f\"Train: {epoch+1}/{epochs}, error={error:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "644a08c0-54dd-4ed1-8b84-77584b1ed44d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T09:25:57.286352Z",
     "iopub.status.busy": "2022-04-14T09:25:57.286105Z",
     "iopub.status.idle": "2022-04-14T09:25:57.291703Z",
     "shell.execute_reply": "2022-04-14T09:25:57.290972Z",
     "shell.execute_reply.started": "2022-04-14T09:25:57.286328Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict function\n",
    "output = X[0]\n",
    "for layer in network:\n",
    "    output = layer.forward(output)\n",
    "    \n",
    "round(output.flatten()[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdaf1ae-d978-45d2-9f98-6f51acfe3064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-python-3.10",
   "language": "python",
   "name": "anaconda-python-3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
